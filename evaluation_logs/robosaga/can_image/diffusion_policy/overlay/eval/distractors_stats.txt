Output from /home/x_zhzhu/RoboSaGA/diffusion_policy/eval.py with arguments --checkpoint ../experiments/robosaga/can_image/diffusion_policy/overlay/checkpoints/epoch=0750-test_mean_score=0.980.ckpt --output_dir ../experiments/robosaga/can_image/diffusion_policy/overlay/eval/distractors/epoch=0750-test_mean_score=0.980.ckpt --distractors:

==================== Double-check the Following Parameters ====================n
Group Norm:  {'enable': True, 'return_fullgrad_bias': True}
Normalize Obs:  True

============= Initialized Observation Utils with Obs Spec =============

using obs modality: low_dim with keys: ['robot0_eef_quat', 'robot0_gripper_qpos', 'robot0_eef_pos']
using obs modality: rgb with keys: ['agentview_image', 'robot0_eye_in_hand_image']
using obs modality: depth with keys: []
using obs modality: scan with keys: []
Diffusion params: 2.556013e+08
Vision params: 2.239418e+07
simple_overlay
SaGA Warning: Buffer is disabled for simple_overlay strategy

==================== Saliency-guided Augmentation Parameters ====================
aug_strategy: simple_overlay
aug_ratio: 0.5
warmup_epochs: 10
update_ratio: None
disable_buffer: True
buffer_shape: [84, 84]
backgrounds shape: [5908, 3, 84, 84]
save_dir: 
mode: encoder_only
======================================================================

Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
{'train/sim_max_reward_0': 0.0, 'train/sim_video_0': '../experiments/robosaga/can_image/diffusion_policy/overlay/eval/distractors/epoch=0750-test_mean_score=0.980.ckpt/media/ixwasqng.mp4', 'train/sim_max_reward_1': 0.0, 'train/sim_video_1': '../experiments/robosaga/can_image/diffusion_policy/overlay/eval/distractors/epoch=0750-test_mean_score=0.980.ckpt/media/cyi0xtgw.mp4', 'train/sim_max_reward_2': 0.0, 'train/sim_max_reward_3': 0.0, 'train/sim_max_reward_4': 0.0, 'train/sim_max_reward_5': 0.0, 'test/sim_max_reward_100000': 1.0, 'test/sim_video_100000': '../experiments/robosaga/can_image/diffusion_policy/overlay/eval/distractors/epoch=0750-test_mean_score=0.980.ckpt/media/4yf9n9y7.mp4', 'test/sim_max_reward_100001': 1.0, 'test/sim_video_100001': '../experiments/robosaga/can_image/diffusion_policy/overlay/eval/distractors/epoch=0750-test_mean_score=0.980.ckpt/media/5ej5ulnr.mp4', 'test/sim_max_reward_100002': 1.0, 'test/sim_video_100002': '../experiments/robosaga/can_image/diffusion_policy/overlay/eval/distractors/epoch=0750-test_mean_score=0.980.ckpt/media/rxjm59hd.mp4', 'test/sim_max_reward_100003': 1.0, 'test/sim_video_100003': '../experiments/robosaga/can_image/diffusion_policy/overlay/eval/distractors/epoch=0750-test_mean_score=0.980.ckpt/media/sosycy2m.mp4', 'test/sim_max_reward_100004': 1.0, 'test/sim_max_reward_100005': 1.0, 'test/sim_max_reward_100006': 1.0, 'test/sim_max_reward_100007': 1.0, 'test/sim_max_reward_100008': 1.0, 'test/sim_max_reward_100009': 1.0, 'test/sim_max_reward_100010': 0.0, 'test/sim_max_reward_100011': 1.0, 'test/sim_max_reward_100012': 1.0, 'test/sim_max_reward_100013': 0.0, 'test/sim_max_reward_100014': 1.0, 'test/sim_max_reward_100015': 1.0, 'test/sim_max_reward_100016': 1.0, 'test/sim_max_reward_100017': 1.0, 'test/sim_max_reward_100018': 0.0, 'test/sim_max_reward_100019': 1.0, 'test/sim_max_reward_100020': 1.0, 'test/sim_max_reward_100021': 1.0, 'test/sim_max_reward_100022': 0.0, 'test/sim_max_reward_100023': 0.0, 'test/sim_max_reward_100024': 1.0, 'test/sim_max_reward_100025': 1.0, 'test/sim_max_reward_100026': 1.0, 'test/sim_max_reward_100027': 1.0, 'test/sim_max_reward_100028': 1.0, 'test/sim_max_reward_100029': 0.0, 'test/sim_max_reward_100030': 0.0, 'test/sim_max_reward_100031': 1.0, 'test/sim_max_reward_100032': 0.0, 'test/sim_max_reward_100033': 0.0, 'test/sim_max_reward_100034': 1.0, 'test/sim_max_reward_100035': 1.0, 'test/sim_max_reward_100036': 1.0, 'test/sim_max_reward_100037': 1.0, 'test/sim_max_reward_100038': 0.0, 'test/sim_max_reward_100039': 0.0, 'test/sim_max_reward_100040': 1.0, 'test/sim_max_reward_100041': 1.0, 'test/sim_max_reward_100042': 1.0, 'test/sim_max_reward_100043': 1.0, 'test/sim_max_reward_100044': 0.0, 'test/sim_max_reward_100045': 1.0, 'test/sim_max_reward_100046': 1.0, 'test/sim_max_reward_100047': 1.0, 'test/sim_max_reward_100048': 1.0, 'test/sim_max_reward_100049': 1.0, 'train/mean_score': 0.0, 'test/mean_score': 0.76}

Output from /home/x_zhzhu/RoboSaGA/diffusion_policy/eval.py with arguments --checkpoint ../experiments/robosaga/can_image/diffusion_policy/overlay/checkpoints/epoch=0700-test_mean_score=0.980.ckpt --output_dir ../experiments/robosaga/can_image/diffusion_policy/overlay/eval/distractors/epoch=0700-test_mean_score=0.980.ckpt --distractors:

==================== Double-check the Following Parameters ====================n
Group Norm:  {'enable': True, 'return_fullgrad_bias': True}
Normalize Obs:  True

============= Initialized Observation Utils with Obs Spec =============

using obs modality: low_dim with keys: ['robot0_eef_pos', 'robot0_gripper_qpos', 'robot0_eef_quat']
using obs modality: rgb with keys: ['robot0_eye_in_hand_image', 'agentview_image']
using obs modality: depth with keys: []
using obs modality: scan with keys: []
Diffusion params: 2.556013e+08
Vision params: 2.239418e+07
simple_overlay
SaGA Warning: Buffer is disabled for simple_overlay strategy

==================== Saliency-guided Augmentation Parameters ====================
aug_strategy: simple_overlay
aug_ratio: 0.5
warmup_epochs: 10
update_ratio: None
disable_buffer: True
buffer_shape: [84, 84]
backgrounds shape: [5908, 3, 84, 84]
save_dir: 
mode: encoder_only
======================================================================

Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
{'train/sim_max_reward_0': 0.0, 'train/sim_video_0': '../experiments/robosaga/can_image/diffusion_policy/overlay/eval/distractors/epoch=0700-test_mean_score=0.980.ckpt/media/nmctdj7o.mp4', 'train/sim_max_reward_1': 0.0, 'train/sim_video_1': '../experiments/robosaga/can_image/diffusion_policy/overlay/eval/distractors/epoch=0700-test_mean_score=0.980.ckpt/media/fs5g0nex.mp4', 'train/sim_max_reward_2': 0.0, 'train/sim_max_reward_3': 0.0, 'train/sim_max_reward_4': 0.0, 'train/sim_max_reward_5': 0.0, 'test/sim_max_reward_100000': 1.0, 'test/sim_video_100000': '../experiments/robosaga/can_image/diffusion_policy/overlay/eval/distractors/epoch=0700-test_mean_score=0.980.ckpt/media/jg47mprj.mp4', 'test/sim_max_reward_100001': 1.0, 'test/sim_video_100001': '../experiments/robosaga/can_image/diffusion_policy/overlay/eval/distractors/epoch=0700-test_mean_score=0.980.ckpt/media/zqw6qemr.mp4', 'test/sim_max_reward_100002': 1.0, 'test/sim_video_100002': '../experiments/robosaga/can_image/diffusion_policy/overlay/eval/distractors/epoch=0700-test_mean_score=0.980.ckpt/media/p3whdu03.mp4', 'test/sim_max_reward_100003': 1.0, 'test/sim_video_100003': '../experiments/robosaga/can_image/diffusion_policy/overlay/eval/distractors/epoch=0700-test_mean_score=0.980.ckpt/media/13yq8koc.mp4', 'test/sim_max_reward_100004': 1.0, 'test/sim_max_reward_100005': 1.0, 'test/sim_max_reward_100006': 1.0, 'test/sim_max_reward_100007': 1.0, 'test/sim_max_reward_100008': 1.0, 'test/sim_max_reward_100009': 1.0, 'test/sim_max_reward_100010': 0.0, 'test/sim_max_reward_100011': 1.0, 'test/sim_max_reward_100012': 1.0, 'test/sim_max_reward_100013': 0.0, 'test/sim_max_reward_100014': 1.0, 'test/sim_max_reward_100015': 0.0, 'test/sim_max_reward_100016': 1.0, 'test/sim_max_reward_100017': 1.0, 'test/sim_max_reward_100018': 0.0, 'test/sim_max_reward_100019': 1.0, 'test/sim_max_reward_100020': 1.0, 'test/sim_max_reward_100021': 1.0, 'test/sim_max_reward_100022': 0.0, 'test/sim_max_reward_100023': 0.0, 'test/sim_max_reward_100024': 1.0, 'test/sim_max_reward_100025': 1.0, 'test/sim_max_reward_100026': 1.0, 'test/sim_max_reward_100027': 1.0, 'test/sim_max_reward_100028': 1.0, 'test/sim_max_reward_100029': 0.0, 'test/sim_max_reward_100030': 0.0, 'test/sim_max_reward_100031': 1.0, 'test/sim_max_reward_100032': 0.0, 'test/sim_max_reward_100033': 0.0, 'test/sim_max_reward_100034': 1.0, 'test/sim_max_reward_100035': 1.0, 'test/sim_max_reward_100036': 1.0, 'test/sim_max_reward_100037': 1.0, 'test/sim_max_reward_100038': 0.0, 'test/sim_max_reward_100039': 0.0, 'test/sim_max_reward_100040': 1.0, 'test/sim_max_reward_100041': 1.0, 'test/sim_max_reward_100042': 1.0, 'test/sim_max_reward_100043': 1.0, 'test/sim_max_reward_100044': 1.0, 'test/sim_max_reward_100045': 1.0, 'test/sim_max_reward_100046': 1.0, 'test/sim_max_reward_100047': 1.0, 'test/sim_max_reward_100048': 1.0, 'test/sim_max_reward_100049': 1.0, 'train/mean_score': 0.0, 'test/mean_score': 0.76}

Output from /home/x_zhzhu/RoboSaGA/diffusion_policy/eval.py with arguments --checkpoint ../experiments/robosaga/can_image/diffusion_policy/overlay/checkpoints/epoch=0650-test_mean_score=0.980.ckpt --output_dir ../experiments/robosaga/can_image/diffusion_policy/overlay/eval/distractors/epoch=0650-test_mean_score=0.980.ckpt --distractors:

==================== Double-check the Following Parameters ====================n
Group Norm:  {'enable': True, 'return_fullgrad_bias': True}
Normalize Obs:  True

============= Initialized Observation Utils with Obs Spec =============

using obs modality: low_dim with keys: ['robot0_eef_quat', 'robot0_eef_pos', 'robot0_gripper_qpos']
using obs modality: rgb with keys: ['robot0_eye_in_hand_image', 'agentview_image']
using obs modality: depth with keys: []
using obs modality: scan with keys: []
Diffusion params: 2.556013e+08
Vision params: 2.239418e+07
simple_overlay
SaGA Warning: Buffer is disabled for simple_overlay strategy

==================== Saliency-guided Augmentation Parameters ====================
aug_strategy: simple_overlay
aug_ratio: 0.5
warmup_epochs: 10
update_ratio: None
disable_buffer: True
buffer_shape: [84, 84]
backgrounds shape: [5908, 3, 84, 84]
save_dir: 
mode: encoder_only
======================================================================

Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
Created environment with name PickPlaceCan
Action size is 7
{'train/sim_max_reward_0': 0.0, 'train/sim_video_0': '../experiments/robosaga/can_image/diffusion_policy/overlay/eval/distractors/epoch=0650-test_mean_score=0.980.ckpt/media/qfn20w3z.mp4', 'train/sim_max_reward_1': 0.0, 'train/sim_video_1': '../experiments/robosaga/can_image/diffusion_policy/overlay/eval/distractors/epoch=0650-test_mean_score=0.980.ckpt/media/lclwm5fc.mp4', 'train/sim_max_reward_2': 0.0, 'train/sim_max_reward_3': 0.0, 'train/sim_max_reward_4': 0.0, 'train/sim_max_reward_5': 0.0, 'test/sim_max_reward_100000': 1.0, 'test/sim_video_100000': '../experiments/robosaga/can_image/diffusion_policy/overlay/eval/distractors/epoch=0650-test_mean_score=0.980.ckpt/media/pgbrc1cf.mp4', 'test/sim_max_reward_100001': 1.0, 'test/sim_video_100001': '../experiments/robosaga/can_image/diffusion_policy/overlay/eval/distractors/epoch=0650-test_mean_score=0.980.ckpt/media/59piaxv7.mp4', 'test/sim_max_reward_100002': 1.0, 'test/sim_video_100002': '../experiments/robosaga/can_image/diffusion_policy/overlay/eval/distractors/epoch=0650-test_mean_score=0.980.ckpt/media/g0vid30r.mp4', 'test/sim_max_reward_100003': 1.0, 'test/sim_video_100003': '../experiments/robosaga/can_image/diffusion_policy/overlay/eval/distractors/epoch=0650-test_mean_score=0.980.ckpt/media/y6wrj0qx.mp4', 'test/sim_max_reward_100004': 1.0, 'test/sim_max_reward_100005': 1.0, 'test/sim_max_reward_100006': 1.0, 'test/sim_max_reward_100007': 1.0, 'test/sim_max_reward_100008': 1.0, 'test/sim_max_reward_100009': 1.0, 'test/sim_max_reward_100010': 0.0, 'test/sim_max_reward_100011': 1.0, 'test/sim_max_reward_100012': 1.0, 'test/sim_max_reward_100013': 0.0, 'test/sim_max_reward_100014': 0.0, 'test/sim_max_reward_100015': 0.0, 'test/sim_max_reward_100016': 1.0, 'test/sim_max_reward_100017': 1.0, 'test/sim_max_reward_100018': 0.0, 'test/sim_max_reward_100019': 1.0, 'test/sim_max_reward_100020': 1.0, 'test/sim_max_reward_100021': 1.0, 'test/sim_max_reward_100022': 0.0, 'test/sim_max_reward_100023': 0.0, 'test/sim_max_reward_100024': 1.0, 'test/sim_max_reward_100025': 1.0, 'test/sim_max_reward_100026': 1.0, 'test/sim_max_reward_100027': 1.0, 'test/sim_max_reward_100028': 1.0, 'test/sim_max_reward_100029': 0.0, 'test/sim_max_reward_100030': 0.0, 'test/sim_max_reward_100031': 1.0, 'test/sim_max_reward_100032': 0.0, 'test/sim_max_reward_100033': 0.0, 'test/sim_max_reward_100034': 1.0, 'test/sim_max_reward_100035': 1.0, 'test/sim_max_reward_100036': 1.0, 'test/sim_max_reward_100037': 1.0, 'test/sim_max_reward_100038': 0.0, 'test/sim_max_reward_100039': 0.0, 'test/sim_max_reward_100040': 1.0, 'test/sim_max_reward_100041': 1.0, 'test/sim_max_reward_100042': 1.0, 'test/sim_max_reward_100043': 1.0, 'test/sim_max_reward_100044': 1.0, 'test/sim_max_reward_100045': 1.0, 'test/sim_max_reward_100046': 1.0, 'test/sim_max_reward_100047': 1.0, 'test/sim_max_reward_100048': 1.0, 'test/sim_max_reward_100049': 1.0, 'train/mean_score': 0.0, 'test/mean_score': 0.74}


===== Results for ../experiments/robosaga/can_image/diffusion_policy/overlay/ =====
Indomain: [0.98, 0.98, 0.98], 0.98 +/- 0.0
  data: [0.98, 0.98, 0.98]
Off-domain for distractors: 0.75 +/- 0.01
   data: [0.76, 0.76, 0.74]
